{"cells":[{"cell_type":"markdown","metadata":{},"source":["Link to the output videos:\n","https://drive.google.com/drive/folders/1Rx1B4Yh8mU1Xba17BvnsSSCxJgRauAid?usp=share_link"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T08:19:26.823867Z","iopub.status.busy":"2024-06-13T08:19:26.823283Z","iopub.status.idle":"2024-06-13T08:19:33.339551Z","shell.execute_reply":"2024-06-13T08:19:33.338587Z","shell.execute_reply.started":"2024-06-13T08:19:26.823835Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import os\n","from tqdm import tqdm\n","from torchvision import transforms\n","import pandas as pd\n","from sklearn.metrics import mean_absolute_error, r2_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T08:19:35.225063Z","iopub.status.busy":"2024-06-13T08:19:35.224220Z","iopub.status.idle":"2024-06-13T08:56:37.175558Z","shell.execute_reply":"2024-06-13T08:56:37.174677Z","shell.execute_reply.started":"2024-06-13T08:19:35.225030Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing /kaggle/input/optical-flow-dataset/train.mp4: 100%|█████████▉| 20399/20400 [37:01<00:00,  9.18it/s]\n"]},{"data":{"text/plain":["[]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["def extract_optical_flow_and_save(video_path, save_path):\n","    if not os.path.exists(save_path):\n","        os.makedirs(save_path)\n","\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    ret, prev_frame = cap.read()\n","    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n","    optical_flows = []\n","\n","    for frame_idx in tqdm(range(total_frames), desc=f'Processing {video_path}'):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n","        hsv = np.zeros_like(frame)\n","        hsv[..., 1] = 255\n","        hsv[..., 0] = angle * 180 / np.pi / 2\n","        hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n","        optical_flow_frame = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","        # optical_flows.append(optical_flow_frame)\n","\n","        output_filename = os.path.join(save_path, f'optical_flow_frame_{frame_idx:04d}.png')\n","        cv2.imwrite(output_filename, optical_flow_frame)\n","\n","        prev_gray = gray\n","\n","    cap.release()\n","    return optical_flows\n","\n","save_path = '/kaggle/working/train_optical'\n","extract_optical_flow_and_save('/kaggle/input/optical-flow-dataset/train.mp4', save_path)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:15:17.404108Z","iopub.status.busy":"2024-06-13T09:15:17.403643Z","iopub.status.idle":"2024-06-13T09:15:17.419412Z","shell.execute_reply":"2024-06-13T09:15:17.418353Z","shell.execute_reply.started":"2024-06-13T09:15:17.404078Z"},"trusted":true},"outputs":[],"source":["def read_speed_data(file_path):\n","    with open(file_path, 'r') as file:\n","        speeds = [float(line.strip()) for line in file.readlines()]\n","    return speeds\n","\n","train_speeds = read_speed_data('/kaggle/input/optical-flow-dataset/train.txt')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:15:50.526155Z","iopub.status.busy":"2024-06-13T09:15:50.525433Z","iopub.status.idle":"2024-06-13T09:15:50.565413Z","shell.execute_reply":"2024-06-13T09:15:50.564684Z","shell.execute_reply.started":"2024-06-13T09:15:50.526122Z"},"trusted":true},"outputs":[],"source":["\n","class OpticalFlowDatasetFromImages(Dataset):\n","    def __init__(self, image_dir, speed_file, transform=None):\n","        self.image_dir = image_dir\n","        self.transform = transform\n","        self.speed_labels = self._load_speed_labels(speed_file)\n","        self.image_files = sorted(os.listdir(image_dir))\n","\n","    def _load_speed_labels(self, speed_file):\n","        speeds = pd.read_csv(speed_file, header=None)\n","        #remove the first one since the optical flow is not computed for first frame\n","        speeds = speeds[1:]\n","        return speeds.values.flatten()\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.image_dir, self.image_files[idx])\n","        image = cv2.imread(img_name)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.resize(image, (0,0), fx=0.5, fy=0.5)\n","        speed = self.speed_labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return {'optical_flow': image, 'speed': speed}\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor() , \n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n","])\n","\n","train_image_dir = '/kaggle/working/train_optical'\n","train_speed_file = '/kaggle/input/optical-flow-dataset/train.txt'\n","# test_image_dir = '/content/drive/My Drive/test_optical'\n","# test_speed_file = '/content/drive/My Drive/test.txt'\n","\n","train_dataset = OpticalFlowDatasetFromImages(train_image_dir, train_speed_file, transform=transform)\n","# test_dataset = OpticalFlowDatasetFromImages(test_image_dir, test_speed_file, transform=transform)\n","\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n","# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:15:58.201893Z","iopub.status.busy":"2024-06-13T09:15:58.201511Z","iopub.status.idle":"2024-06-13T09:15:58.555144Z","shell.execute_reply":"2024-06-13T09:15:58.554273Z","shell.execute_reply.started":"2024-06-13T09:15:58.201863Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SpeedPredictorCNN(\n","  (conv1): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (conv2): Conv2d(24, 36, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (conv3): Conv2d(36, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","  (conv4): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (fc1): Linear(in_features=76800, out_features=100, bias=True)\n","  (fc2): Linear(in_features=100, out_features=50, bias=True)\n","  (fc3): Linear(in_features=50, out_features=10, bias=True)\n","  (fc4): Linear(in_features=10, out_features=1, bias=True)\n","  (relu): ReLU()\n",")\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class SpeedPredictorCNN(nn.Module):\n","    def __init__(self):\n","        super(SpeedPredictorCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2, padding=2)  \n","        self.conv2 = nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=2) \n","        self.conv3 = nn.Conv2d(36, 48, kernel_size=5, stride=2, padding=2) \n","        self.conv4 = nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1)  \n","        self.fc1 = nn.Linear(64 * 30 * 40, 100) \n","        self.fc2 = nn.Linear(100, 50) \n","        self.fc3 = nn.Linear(50, 10)  \n","        self.fc4 = nn.Linear(10, 1) \n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = self.relu(self.conv4(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))  \n","        x = self.fc4(x)\n","        return x\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = SpeedPredictorCNN().to(device)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","print(model)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:16:12.412721Z","iopub.status.busy":"2024-06-13T09:16:12.411902Z","iopub.status.idle":"2024-06-13T09:30:30.163373Z","shell.execute_reply":"2024-06-13T09:30:30.162310Z","shell.execute_reply.started":"2024-06-13T09:16:12.412665Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/5: 100%|██████████| 160/160 [02:52<00:00,  1.08s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Loss: 80.5129\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5: 100%|██████████| 160/160 [02:51<00:00,  1.07s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5, Loss: 62.3347\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5: 100%|██████████| 160/160 [02:51<00:00,  1.07s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/5, Loss: 47.2574\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5: 100%|██████████| 160/160 [02:51<00:00,  1.07s/batch]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/5, Loss: 40.0253\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5: 100%|██████████| 160/160 [02:50<00:00,  1.07s/batch]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/5, Loss: 34.2183\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["num_epochs = 5\n","\n","from tqdm import tqdm\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n","        for batch in train_dataloader:\n","            images = batch['optical_flow'].to(device)\n","            speeds = batch['speed'].float().to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, speeds.unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * images.size(0)\n","\n","            pbar.update(1)\n","\n","    epoch_loss = running_loss / len(train_dataloader.dataset)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T09:30:49.084975Z","iopub.status.busy":"2024-06-13T09:30:49.084139Z","iopub.status.idle":"2024-06-13T09:49:06.736938Z","shell.execute_reply":"2024-06-13T09:49:06.736061Z","shell.execute_reply.started":"2024-06-13T09:30:49.084940Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing /kaggle/input/optical-flow-dataset/test.mp4: 100%|█████████▉| 10797/10798 [18:17<00:00,  9.84it/s]\n"]},{"data":{"text/plain":["[]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["save_path = '/kaggle/working/test_optical'\n","extract_optical_flow_and_save('/kaggle/input/optical-flow-dataset/test.mp4', save_path)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:09:23.140215Z","iopub.status.busy":"2024-06-13T10:09:23.139855Z","iopub.status.idle":"2024-06-13T10:09:23.174258Z","shell.execute_reply":"2024-06-13T10:09:23.173483Z","shell.execute_reply.started":"2024-06-13T10:09:23.140184Z"},"trusted":true},"outputs":[],"source":["test_image_dir = '/kaggle/working/test_optical'\n","test_speed_file = '/kaggle/input/optical-flow-dataset/test.txt'\n","\n","test_dataset = OpticalFlowDatasetFromImages(test_image_dir, test_speed_file, transform=transform)\n","\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:15:46.732299Z","iopub.status.busy":"2024-06-13T10:15:46.731716Z","iopub.status.idle":"2024-06-13T10:18:53.425621Z","shell.execute_reply":"2024-06-13T10:18:53.424337Z","shell.execute_reply.started":"2024-06-13T10:15:46.732268Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing video frames: 100%|██████████| 10797/10797 [03:06<00:00, 57.87it/s]\n"]}],"source":["\n","def create_videos_with_predictions(model, test_video_path, optical_flow_dir, output_path_original, output_path_combined, transform):\n","    cap = cv2.VideoCapture(test_video_path)\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    out_original = cv2.VideoWriter(output_path_original, fourcc, 20.0, (640, 480))\n","    out_combined = cv2.VideoWriter(output_path_combined, fourcc, 20.0, (1280, 480))\n","\n","    model.eval()\n","    frame_idx = 0\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    \n","    for frame_idx in tqdm(range(total_frames-1), desc='Processing video frames'):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        optical_flow_path = os.path.join(optical_flow_dir, f'optical_flow_frame_{frame_idx:04d}.png')\n","        optical_flow_frame = cv2.imread(optical_flow_path)\n","        optical_flow_frame2 = cv2.cvtColor(optical_flow_frame, cv2.COLOR_BGR2RGB)\n","        optical_flow_frame2 = cv2.normalize(optical_flow_frame2, None, alpha=-1, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n","        optical_flow_frame2 = cv2.resize(optical_flow_frame2, (0,0), fx=0.5, fy=0.5)\n","        input_tensor = transform(optical_flow_frame2).unsqueeze(0).float().to(device)\n","        \n","        with torch.no_grad():\n","            speed_prediction = model(input_tensor).item()\n","\n","        original_frame_with_speed = frame.copy()\n","        cv2.putText(original_frame_with_speed, f'Speed: {speed_prediction:.2f}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","        out_original.write(original_frame_with_speed)\n","\n","        combined_frame = cv2.hconcat([frame, optical_flow_frame])\n","        combined_frame_with_speed = combined_frame.copy()\n","        cv2.putText(combined_frame_with_speed, f'Speed: {speed_prediction:.2f}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n","        out_combined.write(combined_frame_with_speed)\n","\n","    cap.release()\n","    out_original.release()\n","    out_combined.release()\n","\n","\n","test_video_path = '/kaggle/input/optical-flow-dataset/test.mp4'\n","output_video_path_original = '/kaggle/working/test_with_predictions_original.avi'\n","output_video_path_combined = '/kaggle/working/test_with_predictions_combined.avi'\n","test_image_dir='/kaggle/working/test_optical'\n","create_videos_with_predictions(model, test_video_path, test_image_dir, output_video_path_original, output_video_path_combined, transform)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:07:37.654972Z","iopub.status.busy":"2024-06-13T10:07:37.654578Z","iopub.status.idle":"2024-06-13T10:07:37.665136Z","shell.execute_reply":"2024-06-13T10:07:37.664103Z","shell.execute_reply.started":"2024-06-13T10:07:37.654942Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original video with predictions:\n"]},{"data":{"text/html":["<a href='test_with_predictions_original.avi' target='_blank'>test_with_predictions_original.avi</a><br>"],"text/plain":["/kaggle/working/test_with_predictions_original.avi"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Combined video with predictions:\n"]},{"data":{"text/html":["<a href='test_with_predictions_combined.avi' target='_blank'>test_with_predictions_combined.avi</a><br>"],"text/plain":["/kaggle/working/test_with_predictions_combined.avi"]},"metadata":{},"output_type":"display_data"}],"source":["from IPython.display import FileLink\n","\n","print(\"Original video with predictions:\")\n","linke = display(FileLink(r'test_with_predictions_original.avi'))\n","\n","print(\"Combined video with predictions:\")\n","display(FileLink(r'test_with_predictions_combined.avi'))"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T10:13:32.443885Z","iopub.status.busy":"2024-06-13T10:13:32.443508Z","iopub.status.idle":"2024-06-13T10:15:00.542655Z","shell.execute_reply":"2024-06-13T10:15:00.541697Z","shell.execute_reply.started":"2024-06-13T10:13:32.443853Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Absolute Error: 4.822\n"]}],"source":["model.eval()\n","model.to(device)\n","actuals = []\n","predictions = []\n","with torch.no_grad():\n","    for data in test_dataloader:\n","        inputs, labels = data['optical_flow'].to(device), data['speed'].to(device)\n","        inputs = inputs.float()\n","        labels = labels.float().view(-1, 1)\n","\n","        outputs = model(inputs)\n","        actuals.extend(labels.cpu().numpy())\n","        predictions.extend(outputs.cpu().numpy())\n","\n","mae = mean_absolute_error(actuals, predictions)\n","r2 = r2_score(actuals, predictions)\n","print(f'Mean Absolute Error: {mae:.3f}')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5181391,"sourceId":8650165,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
